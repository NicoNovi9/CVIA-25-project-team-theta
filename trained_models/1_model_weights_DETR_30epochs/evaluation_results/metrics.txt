======================================================================
DETR EVALUATION RESULTS
Distributed evaluation with 4 GPUs
======================================================================

DETECTION METRICS (COCO)
----------------------------------------------------------------------
mAP@50-95  (AP)      : 0.8952
mAP@50     (AP50)    : 0.9438
mAP@75     (AP75)    : 0.9338
mAR@1      (AR1)     : 0.9293
mAR@10     (AR10)    : 0.9356
mAR@100    (AR100)   : 0.9366

CLASSIFICATION METRICS
----------------------------------------------------------------------
Classification Threshold: 0.3

Class                 Precision     Recall         F1    Support
--------------------------------------------------------------
Cheops                   0.9880     0.9920     0.9900       2000
LisaPathfinder           0.9651     0.9960     0.9803       2000
ObservationSat1          0.9718     0.9805     0.9761       2000
Proba2                   0.9945     0.9940     0.9942       2000
Proba3                   0.9158     0.9305     0.9231       2000
Proba3ocs                0.9478     0.9260     0.9368       2000
Smart1                   0.9865     0.9505     0.9682       2000
Soho                     0.9965     0.9950     0.9957       2000
VenusExpress             0.9989     0.9480     0.9728       2000
XMM Newton               0.9467     0.9865     0.9662       2000
--------------------------------------------------------------

GLOBAL METRICS
----------------------------------------------------------------------
Global Accuracy:     0.9699
Macro Precision:     0.9712
Macro Recall:        0.9699
Macro F1:            0.9704
Weighted Precision:  0.9712
Weighted Recall:     0.9699
Weighted F1:         0.9704

Total images: 20000
Correct: 19398
Incorrect: 583
No detection: 19
Detection rate: 0.9990

======================================================================
