======================================================================
DETR EVALUATION RESULTS
Distributed evaluation with 4 GPUs
======================================================================

DETECTION METRICS (COCO)
----------------------------------------------------------------------
mAP@50-95  (AP)      : 0.9234
mAP@50     (AP50)    : 0.9819
mAP@75     (AP75)    : 0.9729
mAR@1      (AR1)     : 0.9478
mAR@10     (AR10)    : 0.9510
mAR@100    (AR100)   : 0.9514

CLASSIFICATION METRICS
----------------------------------------------------------------------
Classification Threshold: 0.3

Class                 Precision     Recall         F1    Support
--------------------------------------------------------------
Cheops                   0.9761     0.9985     0.9871       2000
LisaPathfinder           0.9975     0.9905     0.9940       2000
ObservationSat1          0.9985     0.9880     0.9932       2000
Proba2                   0.9940     1.0000     0.9970       2000
Proba3                   0.9985     0.9870     0.9927       2000
Proba3ocs                0.9980     0.9870     0.9925       2000
Smart1                   0.9866     0.9940     0.9903       2000
Soho                     0.9995     0.9980     0.9987       2000
VenusExpress             0.9940     0.9930     0.9935       2000
XMM Newton               0.9949     0.9805     0.9877       2000
--------------------------------------------------------------

GLOBAL METRICS
----------------------------------------------------------------------
Global Accuracy:     0.9917
Macro Precision:     0.9938
Macro Recall:        0.9916
Macro F1:            0.9927
Weighted Precision:  0.9938
Weighted Recall:     0.9917
Weighted F1:         0.9927

Total images: 20000
Correct: 19833
Incorrect: 126
No detection: 41
Detection rate: 0.9980

======================================================================
